{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>date</th>\n",
       "      <th>content</th>\n",
       "      <th>replyCount</th>\n",
       "      <th>retweetCount</th>\n",
       "      <th>likeCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RealSkipBayless</td>\n",
       "      <td>[  43   10 2021]</td>\n",
       "      <td>Ja Morant is putting on a SHOW out here in Hol...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RealSkipBayless</td>\n",
       "      <td>[  43   10 2021]</td>\n",
       "      <td>Lakers look by far the best they've looked by ...</td>\n",
       "      <td>55</td>\n",
       "      <td>16</td>\n",
       "      <td>499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RealSkipBayless</td>\n",
       "      <td>[  43   10 2021]</td>\n",
       "      <td>LeBron gets rolled up on, grimaces while he st...</td>\n",
       "      <td>107</td>\n",
       "      <td>101</td>\n",
       "      <td>1488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RealSkipBayless</td>\n",
       "      <td>[  43   10 2021]</td>\n",
       "      <td>Russ (naturally) missed all three of his shots...</td>\n",
       "      <td>51</td>\n",
       "      <td>22</td>\n",
       "      <td>525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RealSkipBayless</td>\n",
       "      <td>[  43   10 2021]</td>\n",
       "      <td>Lakers are on a 25-7 run fueled by defense, fa...</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              user              date  \\\n",
       "0  RealSkipBayless  [  43   10 2021]   \n",
       "1  RealSkipBayless  [  43   10 2021]   \n",
       "2  RealSkipBayless  [  43   10 2021]   \n",
       "3  RealSkipBayless  [  43   10 2021]   \n",
       "4  RealSkipBayless  [  43   10 2021]   \n",
       "\n",
       "                                             content  replyCount  \\\n",
       "0  Ja Morant is putting on a SHOW out here in Hol...           0   \n",
       "1  Lakers look by far the best they've looked by ...          55   \n",
       "2  LeBron gets rolled up on, grimaces while he st...         107   \n",
       "3  Russ (naturally) missed all three of his shots...          51   \n",
       "4  Lakers are on a 25-7 run fueled by defense, fa...          31   \n",
       "\n",
       "   retweetCount  likeCount  \n",
       "0             0          0  \n",
       "1            16        499  \n",
       "2           101       1488  \n",
       "3            22        525  \n",
       "4            30        499  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "\n",
    "username = \"RealSkipBayless\"\n",
    "tweets_df = pd.read_csv('../cleaned-data/user-{}-tweets-cleaned.csv'.format(username))\n",
    "\n",
    "# Displays first 5 entries from dataframe\n",
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There seems to be something wrong with 'ariannahuff'\n",
    "# tweets_df = pd.read_csv('../cleaned-data/user-ariannahuff-tweets-cleaned.csv'.format(username))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Ja Morant is putting on a SHOW out here in Hol...\n",
       "1    Lakers look by far the best they've looked by ...\n",
       "2    LeBron gets rolled up on, grimaces while he st...\n",
       "3    Russ (naturally) missed all three of his shots...\n",
       "4    Lakers are on a 25-7 run fueled by defense, fa...\n",
       "Name: content, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read files and concat -> contents_concat\n",
    "usernames = ['RealSkipBayless', 'ShannonSharpe', 'PatMcAfeeShow', 'stephenasmith', 'maxkellerman',\n",
    "            'EmmaWatson', 'AnnaKendrick47', 'VancityReynolds', 'Matt_Leblanc', 'RobertDowneyJr',\n",
    "            'KingJames', 'KDTrey5', 'Giannis_An34', 'StephenCurry30', 'JoelEmbiid', 'steveaoki',\n",
    "            'CousinStizz', 'trvisXX', 'justinbieber', 'ladygaga', 'mcuban', 'travisk', 'ev', \n",
    "             'TonyRobbins', 'Jsipple', 'informor', 'soumitradutta', \n",
    "            'DrMaureenHanson', 'GeoffreyWCoates']\n",
    "\n",
    "li = []\n",
    "\n",
    "for username in usernames:\n",
    "    tweets_df = pd.read_csv('../cleaned-data/user-{}-tweets-cleaned.csv'.format(username))\n",
    "    li.append(tweets_df)\n",
    "\n",
    "tweets_concat = pd.concat(li, axis=0, ignore_index=True)\n",
    "\n",
    "contents_concat = tweets_concat.loc[:,\"content\"]\n",
    "\n",
    "contents_concat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count word frequency -> freq\n",
    "contents_concat[0].lower()\n",
    "\n",
    "freq = {}\n",
    "\n",
    "for content in contents_concat:\n",
    "    text_string = str(content).lower()\n",
    "    match_pattern = re.findall(r'\\b[a-z]{3,15}\\b', text_string)\n",
    "    for word in match_pattern:\n",
    "        count = freq.get(word,0)\n",
    "        freq[word] = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter stop words\n",
    "# regrex '[a-z]+\n",
    "stopwords = set(\"i,me,my,myself,we,us,our,ours,ourselves,you,your,yours,yourself,yourselves,he,him,his,himself,she,her,hers,herself,it,its,itself,they,them,their,theirs,themselves,what,which,who,whom,whose,this,that,these,those,am,is,are,was,were,be,been,being,have,has,had,having,do,does,did,doing,will,would,should,can,could,ought,i,you,he,she,it,we,they,i,you,we,they,i,you,he,she,we,they,i,you,he,she,we,they,isn,aren,wasn,weren,hasn,haven,hadn,doesn,don,didn,won,wouldn,shan,shouldn,can,cannot,couldn,mustn,let,that,who,what,here,there,when,where,why,how,a,an,the,and,but,if,or,because,as,until,while,of,at,by,for,with,about,against,between,into,through,during,before,after,above,below,to,from,up,upon,down,in,out,on,off,over,under,again,further,then,once,here,there,when,where,why,how,all,any,both,each,few,more,most,other,some,such,no,nor,not,only,own,same,so,than,too,very,say,says,said,shall,x,y,your,yours,yourself,yourselves,you,yond,yonder,yon,ye,yet,z,zillion,j,u,umpteen,usually,us,username,uponed,upons,uponing,upon,ups,upping,upped,up,unto,until,unless,unlike,unliker,unlikest,under,underneath,use,used,usedest,r,rath,rather,rathest,rathe,re,relate,related,relatively,regarding,really,res,respecting,respectively,q,quite,que,qua,n,neither,neaths,neath,nethe,nethermost,necessary,necessariest,necessarier,never,nevertheless,nigh,nighest,nigher,nine,noone,nobody,nobodies,nowhere,nowheres,no,noes,nor,nos,no-one,none,not,notwithstanding,nothings,nothing,nathless,natheless,t,ten,tills,till,tilled,tilling,to,towards,toward,towardest,towarder,together,too,thy,thyself,thus,than,that,those,thou,though,thous,thouses,thoroughest,thorougher,thorough,thoroughly,thru,thruer,thruest,thro,through,throughout,throughest,througher,thine,this,thises,they,thee,the,then,thence,thenest,thener,them,themselves,these,therer,there,thereby,therest,thereafter,therein,thereupon,therefore,their,theirs,thing,things,three,two,o,oh,owt,owning,owned,own,owns,others,other,otherwise,otherwisest,otherwiser,of,often,oftener,oftenest,off,offs,offest,one,ought,oughts,our,ours,ourselves,ourself,out,outest,outed,outwith,outs,outside,over,overallest,overaller,overalls,overall,overs,or,orer,orest,on,oneself,onest,ons,onto,a,atween,at,athwart,atop,afore,afterward,afterwards,after,afterest,afterer,ain,an,any,anything,anybody,anyone,anyhow,anywhere,anent,anear,and,andor,another,around,ares,are,aest,aer,against,again,accordingly,abaft,abafter,abaftest,abovest,above,abover,abouter,aboutest,about,aid,amidst,amid,among,amongst,apartest,aparter,apart,appeared,appears,appear,appearing,appropriating,appropriate,appropriatest,appropriates,appropriater,appropriated,already,always,also,along,alongside,although,almost,all,allest,aller,allyou,alls,albeit,awfully,as,aside,asides,aslant,ases,astrider,astride,astridest,astraddlest,astraddler,astraddle,availablest,availabler,available,aughts,aught,vs,v,variousest,variouser,various,via,vis-a-vis,vis-a-viser,vis-a-visest,viz,very,veriest,verier,versus,k,g,go,gone,good,got,gotta,gotten,get,gets,getting,b,by,byandby,by-and-by,bist,both,but,buts,be,beyond,because,became,becomes,become,becoming,becomings,becominger,becomingest,behind,behinds,before,beforehand,beforehandest,beforehander,bettered,betters,better,bettering,betwixt,between,beneath,been,below,besides,beside,m,my,myself,mucher,muchest,much,must,musts,musths,musth,main,make,mayest,many,mauger,maugre,me,meanwhiles,meanwhile,mostly,most,moreover,more,might,mights,midst,midsts,h,huh,humph,he,hers,herself,her,hereby,herein,hereafters,hereafter,hereupon,hence,hadst,had,having,haves,have,has,hast,hardly,hae,hath,him,himself,hither,hitherest,hitherer,his,how-do-you-do,however,how,howbeit,howdoyoudo,hoos,hoo,w,woulded,woulding,would,woulds,was,wast,we,wert,were,with,withal,without,within,why,what,whatever,whateverer,whateverest,whatsoeverer,whatsoeverest,whatsoever,whence,whencesoever,whenever,whensoever,when,whenas,whether,wheen,whereto,whereupon,wherever,whereon,whereof,where,whereby,wherewithal,wherewith,whereinto,wherein,whereafter,whereas,wheresoever,wherefrom,which,whichever,whichsoever,whilst,while,whiles,whithersoever,whither,whoever,whosoever,whoso,whose,whomever,s,syne,syn,shalling,shall,shalled,shalls,shoulding,should,shoulded,shoulds,she,sayyid,sayid,said,saider,saidest,same,samest,sames,samer,saved,sans,sanses,sanserifs,sanserif,so,soer,soest,sobeit,someone,somebody,somehow,some,somewhere,somewhat,something,sometimest,sometimes,sometimer,sometime,several,severaler,severalest,serious,seriousest,seriouser,senza,send,sent,seem,seems,seemed,seemingest,seeminger,seemings,seven,summat,sups,sup,supping,supped,such,since,sine,sines,sith,six,stop,stopped,p,plaintiff,plenty,plenties,please,pleased,pleases,per,perhaps,particulars,particularly,particular,particularest,particularer,pro,providing,provides,provided,provide,probably,l,layabout,layabouts,latter,latterest,latterer,latterly,latters,lots,lotting,lotted,lot,lest,less,ie,ifs,if,i,info,information,itself,its,it,is,idem,idemer,idemest,immediate,immediately,immediatest,immediater,in,inwards,inwardest,inwarder,inward,inasmuch,into,instead,insofar,indicates,indicated,indicate,indicating,indeed,inc,f,fact,facts,fs,figupon,figupons,figuponing,figuponed,few,fewer,fewest,frae,from,failing,failings,five,furthers,furtherer,furthered,furtherest,further,furthering,furthermore,fourscore,followthrough,for,forwhy,fornenst,formerly,former,formerer,formerest,formers,forbye,forby,fore,forever,forer,fores,four,d,ddays,dday,do,doing,doings,doe,does,doth,downwarder,downwardest,downward,downwards,downs,done,doner,dones,donest,dos,dost,did,differentest,differenter,different,describing,describe,describes,described,despiting,despites,despited,despite,during,c,cum,circa,chez,cer,certain,certainest,certainer,cest,canst,cannot,cant,cants,canting,cantest,canted,co,could,couldst,comeon,comeons,come-ons,come-on,concerning,concerninger,concerningest,consequently,considering,e,eg,eight,either,even,evens,evenser,evensest,evened,evenest,ever,everyone,everything,everybody,everywhere,every,ere,each,et,etc,elsewhere,else,ex,excepted,excepts,except,excepting,exes,enough,http,https,just, still, get, go\".split(\",\"))\n",
    "\n",
    "for key in set(freq.keys()):\n",
    "    if key in stopwords:\n",
    "        freq.pop(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('shannonsharpe', 78198),\n",
       " ('now', 25405),\n",
       " ('like', 20000),\n",
       " ('think', 16002),\n",
       " ('time', 14521)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort frequency map -> 2d array\n",
    "freq_sorted = sorted(freq.items(), key = lambda kv:(kv[1]), reverse = True)\n",
    "freq_sorted[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list->json\n",
    "freq_sorted_json = json.dumps(freq_sorted[0:100])\n",
    "f = open(\"word-freq-sorted.json\", \"w\")\n",
    "f.write(freq_sorted_json)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # list->dict->json\n",
    "freq_sorted_dict = []\n",
    "\n",
    "for i in freq_sorted:\n",
    "    ele = {}\n",
    "    ele[\"text\"] = i[0]\n",
    "    ele[\"value\"] = i[1]\n",
    "    freq_sorted_dict.append(ele)\n",
    "\n",
    "freq_sorted_dict_json = json.dumps(freq_sorted_dict[0:100])\n",
    "f = open(\"word-freq-sorted-full.json\", \"w\")\n",
    "f.write(freq_sorted_dict_json)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
